{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a55e463",
   "metadata": {},
   "source": [
    "Date: 25/07/2022\n",
    "\n",
    "Author: @kavindu404"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bb582",
   "metadata": {},
   "source": [
    "# Multi Class Classification From Scratch (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d0ea1",
   "metadata": {},
   "source": [
    "Welcome to part 2 of the mini blog series on multi class classification from scratch. In first part, we used pixel similarity to predict the class of the digit. In this one, we will be building a simple neural network from scratch. Same as the last one, we start with importing fastai vision library and stacking up the data w.r.t classes like we did in the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6e759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63b7339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.03% [15687680/15683414 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [Path('training'),Path('testing')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc64c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = (path/'training'/'0').ls().sorted()\n",
    "ones = (path/'training'/'1').ls().sorted()\n",
    "twos = (path/'training'/'2').ls().sorted()\n",
    "threes = (path/'training'/'3').ls().sorted()\n",
    "fours = (path/'training'/'4').ls().sorted()\n",
    "fives = (path/'training'/'5').ls().sorted()\n",
    "sixes = (path/'training'/'6').ls().sorted()\n",
    "sevens = (path/'training'/'7').ls().sorted()\n",
    "eights = (path/'training'/'8').ls().sorted()\n",
    "nines = (path/'training'/'9').ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77987917",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_zeros = torch.stack([tensor(Image.open(o)) for o in zeros]).float()/255\n",
    "stacked_ones = torch.stack([tensor(Image.open(o)) for o in ones]).float()/255\n",
    "stacked_twos = torch.stack([tensor(Image.open(o)) for o in twos]).float()/255\n",
    "stacked_threes = torch.stack([tensor(Image.open(o)) for o in threes]).float()/255\n",
    "stacked_fours = torch.stack([tensor(Image.open(o)) for o in fours]).float()/255\n",
    "stacked_fives = torch.stack([tensor(Image.open(o)) for o in fives]).float()/255\n",
    "stacked_sixes = torch.stack([tensor(Image.open(o)) for o in sixes]).float()/255\n",
    "stacked_sevens = torch.stack([tensor(Image.open(o)) for o in sevens]).float()/255\n",
    "stacked_eights = torch.stack([tensor(Image.open(o)) for o in eights]).float()/255\n",
    "stacked_nines = torch.stack([tensor(Image.open(o)) for o in nines]).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20256259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked_zeros, stacked_ones, stacked_twos, stacked_threes, stacked_fours, stacked_fives, stacked_sixes, stacked_sevens, stacked_eights, stacked_nines]).view(-1, 28*28)\n",
    "train_y = tensor([0]*len(zeros)+[1]*len(ones)+[2]*len(twos)+[3]*len(threes)+[4]*len(fours)+[5]*len(fives)+[6]*len(sixes)+[7]*len(sevens)+[8]*len(eights)+[9]*len(nines)).unsqueeze(1)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876372d5",
   "metadata": {},
   "source": [
    "Here, we create a dataset by coupling the image with its label. We do the same for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06516daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dset = list(zip(train_x, train_y))\n",
    "x, y = train_dset[100]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28ba7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_zeros = (path/'testing'/'0').ls().sorted()\n",
    "valid_ones = (path/'testing'/'1').ls().sorted()\n",
    "valid_twos = (path/'testing'/'2').ls().sorted()\n",
    "valid_threes = (path/'testing'/'3').ls().sorted()\n",
    "valid_fours = (path/'testing'/'4').ls().sorted()\n",
    "valid_fives = (path/'testing'/'5').ls().sorted()\n",
    "valid_sixes = (path/'testing'/'6').ls().sorted()\n",
    "valid_sevens = (path/'testing'/'7').ls().sorted()\n",
    "valid_eights = (path/'testing'/'8').ls().sorted()\n",
    "valid_nines = (path/'testing'/'9').ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30508911",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_stacked_zeros = torch.stack([tensor(Image.open(o)) for o in valid_zeros]).float()/255\n",
    "valid_stacked_ones = torch.stack([tensor(Image.open(o)) for o in valid_ones]).float()/255\n",
    "valid_stacked_twos = torch.stack([tensor(Image.open(o)) for o in valid_twos]).float()/255\n",
    "valid_stacked_threes = torch.stack([tensor(Image.open(o)) for o in valid_threes]).float()/255\n",
    "valid_stacked_fours = torch.stack([tensor(Image.open(o)) for o in valid_fours]).float()/255\n",
    "valid_stacked_fives = torch.stack([tensor(Image.open(o)) for o in valid_fives]).float()/255\n",
    "valid_stacked_sixes = torch.stack([tensor(Image.open(o)) for o in valid_sixes]).float()/255\n",
    "valid_stacked_sevens = torch.stack([tensor(Image.open(o)) for o in valid_sevens]).float()/255\n",
    "valid_stacked_eights = torch.stack([tensor(Image.open(o)) for o in valid_eights]).float()/255\n",
    "valid_stacked_nines = torch.stack([tensor(Image.open(o)) for o in valid_nines]).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49068a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([10000, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([valid_stacked_zeros, valid_stacked_ones, valid_stacked_twos, valid_stacked_threes, valid_stacked_fours, valid_stacked_fives, valid_stacked_sixes, valid_stacked_sevens, valid_stacked_eights, valid_stacked_nines]).view(-1, 28*28)\n",
    "valid_y = tensor([0]*len(valid_zeros)+[1]*len(valid_ones)+[2]*len(valid_twos)+[3]*len(valid_threes)+[4]*len(valid_fours)+[5]*len(valid_fives)+[6]*len(valid_sixes)+[7]*len(valid_sevens)+[8]*len(valid_eights)+[9]*len(valid_nines)).unsqueeze(1)\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b96d278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcf841",
   "metadata": {},
   "source": [
    "In the FastAI book, Jeremy explain a 7-step process that we gonna follow. The steps are as below;\n",
    "\n",
    "1. *Initialize* the weights.\n",
    "1. For each image, use these weights to *predict* the class.\n",
    "1. Based on these predictions, calculate how good the model is (its *loss*).\n",
    "1. Calculate the *gradient*, which measures for each weight, how changing that weight would change the loss\n",
    "1. *Step* (that is, change) all the weights based on that calculation.\n",
    "1. Go back to the step 2, and *repeat* the process.\n",
    "1. Iterate until you decide to *stop* the training process (for instance, because the model is good enough or you don't want to wait any longer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcdfa34",
   "metadata": {},
   "source": [
    "So first, we write a function to init the weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5acf923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf7c522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = init_param((28*28, 10))\n",
    "bias = init_param(10)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6957410",
   "metadata": {},
   "source": [
    "In order to predict the class, we need a small model. So in the following function, we take the data as input and outputs the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "074948c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb): return xb@weights+bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86c7b3",
   "metadata": {},
   "source": [
    "Then, in the next step, we need a way to calculate the loss for the predictions. There are liple loss functions available depending on the application. In this case, we need a loss function that can compute the loss in a muti-categorical problem. Softmax is the most common loss function used in such cases. It requires all the predictions to sum to 1 and it tends to push the most likely activation to a much larger value compared to others.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccbcc580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x): return torch.exp(x)/torch.exp(x).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b092df",
   "metadata": {},
   "source": [
    "So now we define crossentropy loss to first apply softmax to the predictions and then to calculate the loss comparing them to the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8f36ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy_loss(inputs, targets):\n",
    "    activations = softmax(inputs)\n",
    "    return -activations[range(inputs.shape[0]), targets].log().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef458695",
   "metadata": {},
   "source": [
    "Okay now we create dataloader objects for both training and validation sets. Note that each data point is having 784 features (28 * 28) and a corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7275d82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(train_dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d686449",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3425a",
   "metadata": {},
   "source": [
    "Let's grab a subset of the training set and get their predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66b2f7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc7ae6",
   "metadata": {},
   "source": [
    "Note that for each input, there are 10 outputs. Once we input them to the softmax loss function, it outputs those 10 values in a way that they add up to 1 with the most probable labels with higher values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20ee77ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(batch)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca766c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.7473, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = crossentropy_loss(preds, train_y[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e976e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 10]),\n",
       " tensor(2.4328e-10),\n",
       " tensor([-9.9999e-01,  7.6655e-01,  1.7359e-07,  5.4389e-04,  5.4135e-02,\n",
       "          3.6396e-07,  1.7450e-01,  4.2626e-03,  3.9071e-06,  2.6428e-07]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "weights.grad.shape,weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4087a5",
   "metadata": {},
   "source": [
    "Now we put all the steps together to calculate the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb2c6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = crossentropy_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b2244",
   "metadata": {},
   "source": [
    "Next we define the following function to train our model for a single epoch. It will take each batch from the data loader and will calculate the gradients. Then it will update the weights accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4292418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, param):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1aa6a6",
   "metadata": {},
   "source": [
    "Finally, we can package them allto train for multiple epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3f35319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,lr, param, epochs):\n",
    "    val_acc = []\n",
    "    for i in range (epochs):\n",
    "        train_epoch(model, lr, param)\n",
    "        val_acc.append(validate_epoch(model))\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc38c37",
   "metadata": {},
   "source": [
    "We also define functions to calculate train and validation accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a6c54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(preds,yb):\n",
    "    correct=preds.max(axis=1)[1]==yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8fe001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9404ce4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.lines.Line2D at 0x7f7b07cfe5f0>], 0.621)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = init_param((28*28, 10))\n",
    "bias = init_param(10)\n",
    "params = weights,bias\n",
    "lr = 1e-1\n",
    "val_acc=(train_model(linear1, lr, params, 100))\n",
    "plt.plot(range(100), val_acc), val_acc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee4523",
   "metadata": {},
   "source": [
    "So our simple neural network is capable of classifying digits with a validation accuracy of 0.621"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
